# 为什么工具、MCP、技能和代理会出现：理解 AI 系统背后的架构

*上下文窗口和结构化思维如何塑造了 AI 抽象的演进*

---

## 梦想与现实

想象一个完美的 AI 助手：你告诉它你需要什么，它就……做到了。完全地、准确地、自主地完成。不需要后续提问，不需要中间步骤，不需要工具或框架。

我们还没有达到那个目标。而这个梦想与当今现实之间的差距催生了整个生态系统：**工具**、**MCP 服务器**、**技能**和**代理**。

如果你一直关注 AI 的发展，你会发现这些术语无处不在。但你是否想过它们为什么会出现？为什么我们不能直接与模型对话？

答案揭示了关于 AI 实际工作方式的一些基本问题。这些抽象不是随机的工程时尚——它们是对两个硬约束的精确响应：

1. **模型并非无所不知**：它们基于历史数据训练，被冻结在某个时间点，无法访问你的数据库或今天的新闻
2. **复杂性需要结构**：就像你需要待办事项清单来管理复杂项目一样，模型需要结构化框架来管理多步骤任务

这里有一个将所有内容联系在一起的洞察：**现代 AI 中的每一个抽象——从简单的工具到复杂的代理工作流——都是为了解决上下文窗口问题，同时通过结构提高准确性**。

让我们展开讨论这是如何发展的。

## 工具：当代码成为接口

### 为什么不每次都生成代码？

这里有一个思想实验：与其给模型提供预构建的工具，为什么不让它们为每个任务编写自定义代码呢？

需要获取网页？模型用 requests 编写一个 Python 脚本。
需要查询数据库？它生成 SQL 和连接处理代码。
需要处理 PDF？它从头开始编写解析器。

技术上可行。实际上是灾难。

**三个致命问题：**

- **Token 浪费**：为每个操作生成实现代码会耗尽你的上下文窗口。一个简单的网络搜索可能在做任何有用的事情之前就消耗了 500+ tokens 的样板代码。
- **可靠性**：在时间压力下编写的代码（或由 AI 编写）会有 bug。而经过实战检验的库不会。
- **冗余性**：为什么要在一次对话中重新生成相同的数据库连接代码 100 次？

### 突破：接口优于实现

工具将软件工程的核心原则带到了 AI：**抽象**。

模型不再生成代码，而是调用命名函数：

```
❌ 之前："生成代码来搜索网络、处理速率限制、
           解析 HTML、提取文本、处理错误……"

✅ 之后：WebSearch(query="latest AI news")
```

发生了什么变化？我们：
1. 预先构建了稳定、经过测试的常见操作实现
2. 用结构化模式（输入、输出、目的）描述它们
3. 让模型通过名称调用它们，而不是重新实现

这与编程中的函数逻辑相同：编写一次，到处使用。

### 它们解决的约束

工具将冗长的实现细节压缩成简洁的接口。500-token 的代码生成变成了 50-token 的函数调用。这节省了 10 倍的上下文。

但问题是：**工具仍然是原子操作**。它们是狭窄、特定的能力。你解决了代码生成问题，但没有解决集成问题。

## MCP：AI 的 API 网关

### 集成噩梦

工具解决了一个问题，但创造了另一个问题。想象一下，你正在构建一个需要以下功能的 AI 助手：

- 查询你的 PostgreSQL 数据库
- 从 Salesforce 获取数据
- 从 Google Drive 读取文件
- 从 Datadog 拉取指标

每个系统都有自己的接口：
- 不同的认证机制（API 密钥、OAuth、服务账户）
- 不同的查询语言（SQL、SOQL、REST APIs）
- 不同的错误处理模式
- 不同的速率限制规则

现在你需要向模型描述所有这些。你的上下文窗口充满了：
- "这是如何连接到 Postgres……"
- "这是 Salesforce 认证流程……"
- "这是 Google Drive API 文档……"

将这个数字乘以 20 个不同的系统，在模型做任何实际工作之前，你就淹没在集成代码中了。

### 标准化解决方案

**模型上下文协议（MCP）**是应用于 AI 的"API 网关"模式。一个协议统治所有。

不再是这种混乱：
```
代理 → 自定义 Postgres 接口 → 数据库
    → 自定义 Salesforce 接口 → CRM
    → 自定义 Drive 接口 → 文件
    → （在上下文中描述每个接口……）
```

你得到这种清晰：
```
代理 → MCP 协议 → MCP 服务器（Postgres）
                → MCP 服务器（Salesforce）
                → MCP 服务器（Drive）
                → （统一接口描述）
```

**MCP 服务器公开的内容：**
- **资源**：你的数据，无论它在哪里（数据库、文件、APIs）
- **工具**：以相同方式工作的标准化函数调用
- **提示**：可重用的指令模板

可以这样想：在 HTTP 之前，每个应用程序协议都不同。HTTP 之后，每个人都说同一种语言。MCP 正在为 AI 到系统的通信做同样的事情。

### 它没有解决的问题

MCP 使集成*更容易*，但它并没有消除上下文成本。你仍然需要告诉模型：
- "这些 MCP 服务器可用……"
- "这是每个服务器可以做的……"
- "这是它们支持的操作……"

描述更短且标准化，但仍然消耗上下文。集成问题现在变成了*发现问题*：哪些 MCP 服务器对这个任务重要？

## 技能：工作流层

### 编排问题

工具非常适合单个操作。但真正的工作不是原子的——它是组合的。

考虑一个常见任务："分析这份合同 PDF 并生成合规报告。"

实际需要发生的事情：
1. 从 PDF 中提取文本（工具：PDF 解析器）
2. 识别关键条款（工具：NLP 分析）
3. 根据合规规则检查（工具：规则引擎）
4. 计算风险分数（工具：风险计算器）
5. 生成包含发现的报告（工具：文档生成器）
6. 格式化为 PDF（工具：PDF 创建器）

没有技能，你需要：
- **加载所有这些工具**到上下文中（描述、参数、示例）
- **让模型每次从头开始规划**序列
- **希望它选择**正确顺序的正确工具

现在想象你有 100 个可用工具。模型如何知道使用哪 6 个？你面临**组合爆炸**：太多可能性，太多上下文，太多规划开销。

### 组合解决方案

技能是**打包为更高级别抽象的工作流**。

不再是这样：
```
上下文：
- PDFParser(file) → 提取文本
- NLPAnalyzer(text) → 识别实体
- RulesEngine(entities, rules) → 检查合规性
- RiskCalculator(results) → 评分风险
- DocumentGenerator(data, template) → 创建报告
- PDFCreator(document) → 输出 PDF

模型：*从头开始规划序列*
```

你得到这个：
```
上下文：
- AnalyzeContractCompliance(pdf_file, rules) → 生成合规报告

模型：*直接使用技能*
```

**技能封装的内容：**
1. **工具序列**：经过验证的操作顺序
2. **最佳实践**：如何处理边缘情况和错误
3. **领域知识**：在这个工作流中什么是"好的"

技能之于工具，就像函数之于原始操作——一个命名的、可重用的模式，压缩复杂性。

### 信任问题

这里有一个有趣的张力：技能包含*规定性指导*。它们告诉模型"这样做"。

这意味着**我们不完全信任模型能独自解决**。坦率地说——模型在复杂的多步骤规划中确实可能遇到困难，特别是当步骤依赖于先前的结果时。

但有一个哲学问题：我们应该只在*证明*模型无法处理后才添加这种指导吗？还是应该主动编码专业知识？

务实的答案：**技能是一种赌注**。上下文节省和可靠性收益超过了模型自主性的损失。目前是这样。

### 新问题

技能解决了局部复杂性，但创造了全局复杂性：**技能激增**。

如果你有 50 个技能，你又回到了上下文爆炸——模型需要所有 50 个的描述来选择正确的。你只是将发现问题推到了更高一层。

这就是下一个抽象出现的地方：代理。

## 代理：专业化层

### 不可能的选择

你构建了一个通用 AI 助手。它需要处理：
- 代码审查（需要编程工具、linters、测试框架）
- 数据分析（需要 SQL、pandas、可视化库）
- 客户支持（需要 CRM 集成、工单系统、知识库）
- 内容写作（需要研究工具、SEO 检查器、发布 APIs）

**选项 A**：将所有内容加载到上下文中
- 结果：在开始之前就有 10,000 tokens 的工具描述
- 问题：上下文爆炸

**选项 B**：只使用通用工具
- 结果：没有领域专业知识，通用响应
- 问题：你留下了 80% 的潜在价值

这是**通才困境**：要么处处肤浅，要么无处深入。

### 专业化解决方案

**代理引入了领域分区**。与其一个瑞士军刀，不如为特定工作准备专门的工具。

实际例子：

**CodeReviewAgent**
- 工具：ESLint、pytest、git、代码搜索
- 知识：整洁代码原则、安全模式
- 上下文：1,200 tokens

**DataAnalyticsAgent**
- 工具：SQL 执行器、pandas、plotly、统计库
- 知识：统计方法、可视化最佳实践
- 上下文：1,100 tokens

**CustomerSupportAgent**
- 工具：CRM API、工单系统、FAQ 搜索
- 知识：支持协议、升级程序
- 上下文：900 tokens

每个代理都是**上下文高效的**，因为它只加载对其领域重要的内容。代码审查不需要 SQL 工具。支持工单不需要 linting。

**代理提供的内容：**
- **精选工具集**：只有对该领域重要的工具
- **领域提示**：专门的指令和心智模型
- **专家知识**：融入初始上下文的最佳实践

代理甚至可以调用其他代理——创建分层任务分解。一个"全栈开发"代理可能编排代码审查代理、测试代理和部署代理。

### 编排的代价

专业化解决了上下文污染，但创造了一个新问题：**路由复杂性**。

哪个代理处理"分析这个数据集并生成报告"？是数据分析还是商业智能？如果报告需要图表，你需要可视化代理吗？

你已经将复杂性推高了一层：现在你需要**元代理**或路由逻辑来决定哪个专家处理什么。

关键的是：随着模型变得更智能，专业化代理的价值**会降低**。一个足够强大的通用模型可能不需要预加载的领域知识——它可以推理出来。

但我们还没有到那一步。目前，专业化获胜。

## 人类角色：上下文策划作为关键工作

在关于 AI 代理的讨论中，经常被忽视的是：**有人必须组织进入初始上下文的内容**。这不是简单的工作——这是必不可少的专业知识。

### 代码索引类比

为代理选择工具和技能与**索引大型代码库**是同样的问题：

| 问题 | 解决方案 | 挑战 |
|---------|----------|-----------|
| IDE：在数百万行代码中查找相关函数 | 构建语义索引 | 哪些函数对这个任务重要？ |
| 代理：在数千个能力中查找相关工具 | 策划工具/技能集 | 哪些工具对这个领域重要？ |

**通用代理**动态解决这个问题——它们按需搜索、查询和发现工具。

**专业化代理**从**预先策划的上下文**中获得优势。人类专家已经回答了：
- 哪些工具对这个领域真正重要？
- 哪些工具组合可以可靠地协同工作？
- 哪些方法是经过实战检验的，哪些是实验性的？

这不是限制——这是**编码的专业知识**。你将人类判断融入代理的起点。

### 发现问题：从无限选项中选择

想象一下，互联网上有 10,000 个可用工具。代理——通用或专业化——如何选择正确的？

**两种机制：**

**1. 网络搜索**（用于当前的、不断发展的知识）
```
查询："Python 中最好的 PDF 解析库 2025"
结果：PyPDF2 vs. pdfplumber vs. 更新的替代品
```

**2. 训练记忆**（用于已建立的模式）
```
模型见过："pandas 是 Python 中数据操作的标准"
它知道：requests → 网络调用，SQLAlchemy → 数据库工作
```

通用代理**实时**使用这些机制——实时搜索和推理。

专业化代理使用**人类捷径**——领域专家已经预先回答了这些问题并将正确的工具捆绑在一起。

### 持续适应循环

现实是：这不是一次性设置。

生态系统在演变：
- 新工具推出（更好的替代品）
- 最佳实践转变（去年有效的现在已弃用）
- 集成模式改进（组合工具的更简单方法）

这创造了一个**持续的反馈循环**：

```
1. 人类结构化信息 → 策划工具、技能、上下文
2. AI 使用该结构 → 完成任务，识别差距
3. AI 能力扩展 → 可以更自主地处理
4. 人类重构结构 → 移除不必要的脚手架
5. 循环继续
```

这不是"设置好就忘记"。这是人类专业知识和 AI 能力之间的**持续共同演化**。

问题不是"AI 会取代这项人类工作吗？"而是"随着 AI 变得更智能，这项工作的性质如何变化？"

## 统一理论：都是关于上下文的

现在我们可以看到模式。每一个抽象——从简单的工具到复杂的代理——都是为了解决**同一个基本问题：上下文窗口限制**。

### 上下文压缩层次结构

| 层 | 它压缩的内容 | 上下文节省 | 示例 |
|-------|-------------------|-----------------|---------|
| **工具** | 实现代码 | 10x | 500 tokens 代码 → 50 token 函数调用 |
| **MCP** | 集成细节 | 3x | 自定义接口 → 统一协议 |
| **技能** | 多工具工作流 | 20x | 20 个工具描述 → 1 个技能描述 |
| **代理** | 领域知识 | 100x | 10,000 通用 tokens → 1,000 专业 tokens |

每一层都**压缩更多上下文**，使相同窗口内的更复杂任务成为可能。

### 结构优势

但还有第二阶效益：**结构提高准确性**。

当你强制使用明确的接口和组合时，你：
- **减少决策空间**：更少的选择意味着更少的错误转向
- **编码最佳实践**：经过验证的模式胜过即兴发挥
- **启用验证**：结构化输出可以被验证

可以这样想：一个不受约束的模型就像一个没有大纲的人类作家。一个拥有工具、技能和代理的模型就像一个拥有模板、风格指南和编辑的作家。两者都可以产生内容，但结构化方法更可靠。

## 发展轨迹：不断推进的边界

转折点在于：**这一切都不是静态的**。"通用代理"和"专业化代理"之间的界线每次模型改进时都会推进。

### 能力边界的持续推进

观察模型变强时发生的事情：

**2023：GPT-3.5 时代**
```
通用代理：可以编写基本代码，回答问题
需要专业化代理：领域工作、复杂规划、多步骤任务
```

**2024：GPT-4 时代**
```
通用代理：处理领域基础、简单多步骤任务
需要专业化代理：专家级工作、优化工作流
```

**2025：Claude Opus 4.5 时代**
```
通用代理：专家级推理、复杂编排
需要专业化代理：性能优化、成本效率
```

**未来状态**
```
通用代理：自主处理 95% 的任务
专业化代理：提供最后 5% 的优化或利基专业知识
```

模式：**去年需要专业化代理的东西今天可能用通用代理就能工作**。

这并不意味着专业化消失——它意味着**阈值上升**。专业化从"正确性必需"转向"效率有价值"。

### 持续适应周期

这创造了一个永恒的演化：

```mermaid
1. 人类结构化信息
   ↓
2. AI 有效使用该结构
   ↓
3. AI 能力扩展
   ↓
4. 一些结构变得不必要
   ✓
5. 人类为新现实重构
   ↓
   [循环回到 1]
```

**具体例子：**

- **2023**：你需要一个专业化的"SQL 查询生成"代理，因为通用模型在复杂连接上挣扎
- **2024**：通用模型可以做基本 SQL，所以你专门化为"优化查询规划"
- **2025**：通用模型也处理优化，所以你专门化为"特定数据库性能调优"

人类和 AI 之间的关系是**持续的协商**：

- 人类决定结构化什么 vs. 让 AI 弄清楚什么
- AI 不断扩展的能力改变了这条线的落点
- 双方持续适应新的平衡

### 这对构建者意味着什么

**今天的最佳实践：**
- 结构化知识以适应上下文窗口 *（但窗口正在扩大）*
- 模块化能力以实现可靠性 *（但模型正在改进）*
- 专业化代理以获得领域专业知识 *（但通用代理正在赶上）*

**明天的最佳实践：**
- **自适应架构**：根据模型能力扁平化或加深的系统
- **动态专业化**：根据任务复杂性调整深度的代理
- **进化设计**：为变化而构建，而非为当前状态

**关键原则：不要为今天的限制而优化。为持续演化而设计。**

你今天解决问题 X 的专业化代理在 6 个月后通用模型可以做到时可能就过时了。相应地计划。

## 结论：为持续进化而构建

让我们总结一下。

**工具、MCP、技能和代理不是独立的发明**——它们是对两个基本约束的同一解决方案的层次：

1. **有限的上下文窗口**：我们必须压缩告诉模型的内容
2. **有界推理**：模型在有结构的情况下比完全自由时表现更好

但有趣的是：**这些约束正在变化**。

上下文窗口正在扩大（128k → 200k → 1M → 10M tokens）。推理正在改进（GPT-3.5 → GPT-4 → Claude Opus 4.5）。去年需要仔细结构化的东西今天可能自动工作。

### 动态环境的三个原则

**1. 带着过时意识进行结构化**

构建抽象，但要知道它们有有效期：

- 反复生成代码？→ **构建工具** *（但模型最终会原生做到）*
- 集成许多系统？→ **使用 MCP** *（标准化具有持久价值）*
- 编排工具序列？→ **创建技能** *（但注意模型何时可以自主规划）*
- 一个代理中太多领域？→ **专业化** *（但阈值不断提高）*

**2. 拥抱人类-AI 伙伴关系**

这不是交接——这是持续协作：

- **人类为专业化代理策划上下文**（关键专业知识工作）
- **AI 在执行时发现差距**和新模式
- **人类随着 AI 能力增长重构结构**
- **循环无限期继续**

问题不是"AI 何时接管？"而是"随着 AI 改进，我们的角色如何演变？"

**3. 为演化而设计，而非当前状态**

构建可以适应的系统：

- 不要创建假设当前能力水平的刚性层次结构
- 构建可以动态**扁平化**（移除结构）或**加深**（添加结构）的代理
- 接受通用/专业化边界是不断协商的
- 计划你的专业化代理变得不必要

### 主线：新范式中的永恒原则

我们讨论的一切都回到**模块化思维**——这是推动软件工程 50 多年的同一原则。

我们只是将它应用于一个新范式，其中：

- **上下文是约束**（但它正在扩大）
- **结构启用能力**（但太多会成为开销）
- **专业化增加价值**（但通用能力正在侵蚀）

艺术不仅在于知道*哪个*抽象使用。而在于知道该抽象将*多久*保持价值。

### 真正的挑战

我们不是为今天的 AI 而构建。我们在为**持续共同演化**而构建：

- 人类专业知识 ↔ AI 能力
- 结构 ↔ 自主性
- 专业化 ↔ 通用

这就是游戏。不是"设置好就忘记"，而是"构建、测量、适应、重复"。

---

**核心要点：**你今天构建的每个工具、MCP 服务器、技能和代理都是对一个不断演化问题的临时解决方案。要好好构建它们，但更要让它们能够演化。

AI 工程的未来不是构建完美的抽象。而是构建**优雅适应**的系统，随着底层智能的增长。

这才是真正的机会。

## 更深层的模式：人类的工具制造使命

### 我们一直是工具建造者

从 AI 中退后一步。从不同的角度看人类历史：**我们是一个永不停止创造工具的物种，只是为了用更好的工具取代它们**。

- 石器 → 青铜器 → 铁器 → 钢器 → 复合材料
- 算盘 → 机械计算器 → 电子计算器 → 电子表格软件
- 电报 → 电话 → 电子邮件 → Slack
- 马车 → 蒸汽机 → 内燃机 → 电动汽车

模式是普遍的：**每一个工具层都建立在前一个之上，使以前看似不可能的能力成为可能**。铁器时代并没有抹去我们从青铜器中学到的东西——它建立在其上。

AI 工具、MCP、技能和代理正在发生的事情并不新鲜。这是**同样的进化过程**，只是移动得更快：

```
代码库（1960s-1990s）
   ↓
APIs 和 web 服务（2000s）
   ↓
云函数和微服务（2010s）
   ↓
AI 工具和 MCP 服务器（2020s）
   ↓
代理编排层（现在）
   ↓
[接下来会发生什么]
```

每一层都使前一层更易访问、更可组合、更强大。你不再编写汇编代码——但有人必须这样做，这样你才能编写 Python。你不再管理服务器——但有人必须这样做，这样你才能用一个命令部署。

**工具不仅仅解决问题。它们为下一代工具创造平台。**

### 前所未有的需求：为 AI 结构化

但这个时代的不同之处在于：**AI 创造了对人类结构化能力的普遍、前所未有的需求**。

在以前的技术浪潮中，结构化是专家工作：
- 程序员结构化代码
- 数据库设计师结构化数据
- 建筑师结构化建筑
- 科学家结构化实验

**大多数人从不需要考虑结构。**他们只是使用输出。

AI 完全改变了这一点。

现在，**要从 AI 中获得价值，你必须结构化你的意图**：

- **提示工程**是结构化你的问题
- **工具设计**是结构化你的能力
- **技能创建**是结构化你的工作流
- **代理配置**是结构化你的领域知识

这不是可选的。这不是给专家的。**这是任何使用 AI 系统的人的基本要求。**

想想这意味着什么：

营销经理需要结构化营销活动工作流。
客户支持主管需要结构化升级程序。
内容创作者需要结构化研究和发布管道。
研究人员需要结构化数据分析协议。

**结构化能力不再是专业技能——它是普遍的素养要求。**

### 结构价值的上升

这里有一个将所有内容联系在一起的洞察：**随着 AI 变得更强大，结构化变得更有价值，而不是更少**。

这似乎违反直觉。更好的 AI 不应该意味着你需要更少的结构吗？

不。原因如下：

**1. 复杂性随能力扩展**

更好的 AI 处理更难的问题。更难的问题有更多的边缘情况、更多的约束、需要更多的领域知识。你需要更多的结构来有效地利用这种力量。

**2. 高风险决策需要护栏**

随着 AI 从"有用的助手"转向"做出真实决策的自主代理"，错误的成本上升。结构提供：
- 验证边界
- 质量检查点
- 可解释性框架
- 回滚机制

**3. 协作需要共同理解**

AI 系统不是孤立工作的——它们与人类和其他 AI 系统一起工作。结构是使协作成为可能的**共同语言**：

```
人类 ←(结构)→ AI 代理 ←(结构)→ 工具
      ←(结构)→ 其他代理 ←(结构)→ 系统
```

没有结构，你就有混乱。有了结构，你就有了编排。

**4. 效率需要有意设计**

是的，通用代理可以弄清楚。但"弄清楚"花费 tokens、时间和可靠性。**结构良好的系统效率是 10x-100x**，因为它们跳过探索阶段，直接执行。

AI 越好，你就越想**将其原始力量与人类策划的结构结合**以获得最大效率。

### 永久性转变：结构作为核心能力

我们正在见证的不是一个临时阶段。这是**结构化能力作为核心人类能力的永久提升**。

工作的未来不是"AI 取代人类"或"人类监督 AI"。而是：

**人类结构化问题空间 → AI 在该结构内执行 → 人类根据结果优化结构 → 持续改进循环**

这就是为什么我们讨论的抽象——工具、MCP、技能、代理——如此重要。它们**不仅仅是技术解决方案。它们是这种新素养的训练场。**

当你设计工具接口时，你在学习结构化能力。
当你创建 MCP 服务器时，你在学习结构化集成。
当你构建技能时，你在学习结构化工作流。
当你配置代理时，你在学习结构化领域专业知识。

**每个抽象都在教导人类如何以 AI 可以放大的结构思考。**

### 机会：结构化人才的崛起

这里有一个大胆的预测：**下一代高价值工作将由擅长为 AI 系统结构化复杂性的人主导**。

不仅仅是程序员。任何能够：
- 识别混乱过程中的模式
- 定义组件之间的清晰接口
- 将专业知识编码为可重用模板
- 设计平衡灵活性和约束的系统
- 随着能力变化演化结构

称他们为"AI 架构师"、"系统设计师"、"编排专家"——头衔不重要。重要的是技能：**将混乱的现实转化为 AI 可以增强的结构化系统**。

这是**大多数人预期的反面**。我们认为 AI 会减少仔细思考和规划的需要。相反，**它使结构化思维比以往任何时候都更有价值**。

### 永恒的真理：工具在工具之上构建，永远

让我们回到我们开始的地方：**人类一直在构建工具，替换它们，并在它们之上构建新工具**。

现在不同的是速度。在石器时代需要几个世纪，在工业时代需要几十年，现在在 AI 时代只需要几年——或几个月。

但模式保持不变：
- 我们创建压缩复杂性的抽象
- 这些抽象启用新能力
- 新能力创造新问题
- 我们创建新抽象来解决它们
- 循环继续，更快

**AI 没有发明这个循环。它加速了它。**

在这个加速的世界中，**结构化的能力——在正确的时间创建正确的抽象——成为最高杠杆技能**。

不是因为 AI 不能思考。而是因为 AI 思考*如此强大*，以至于非结构化探索会浪费其潜力。结构是我们如何**将这种力量集中**在重要的问题上。

---

*你在构建什么抽象？你如何规划它们的演化？我很想听听你对如何在这个不断演化的环境中前行的想法。*
